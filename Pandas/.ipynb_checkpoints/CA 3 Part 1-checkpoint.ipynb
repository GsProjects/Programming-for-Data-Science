{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gearoid Lacey C00183380\n",
    "Data quality issues and improvements\n",
    "#NOTE: The following code assumes the 'Food_Inspections.csv' file is in the same directory as the notebook\n",
    "The first data quality issue I know exists is different spellings of the same DBA name. To attempt to counteract this I intend to change all DBA names to lowercase and remove any apostrophes, commas full stops and hypens. I will also remove leading and trailing whitespace. I also perform some amendments to the variations of the names mcdonalds, subway, dunkin donuts, 7 eleven and kfc.\n",
    "\n",
    "\n",
    "Another issue I intend to fix is location data being stored as seperate values and also in a combined string in the location column. From my initial inspections the location data in the location column appears to be more accurate so removing the seperate location rows would appear to be the better option. I initially populate the location column if its empty by creating a tuple and storing the values from the latitude and longitude columns in it. There are also some outliers regarding the location, longitude and latitude rows. There were rows without any location latitude or longitude data but I still keep these rows as theres also an address and zip code which could be used to locate a premises. Note there where no rows missing an address value.\n",
    "\n",
    "\n",
    "Empty cells are populated with the value 'null'\n",
    "I also noticed that some rows are missing information, therefore I chose to populate these rows with the value null as they are predominatly text based. If they were numerically based then you could potentially fill the missing values with a zero to keep the rows.\n",
    "\n",
    "In rows that are missing an AKA Name I will copy in the DBA Name. Or in rows that are missing a DBA Name I copy in the AKA Name. Although the AKA Name is not the legal name of the business copying the AKA Name into the DBA Name may still be useful as they are often quite similar.\n",
    "\n",
    "As the data is based on premises's in Chicago Illinois, the state column was dropped.\n",
    "\n",
    "\n",
    "I noticed that some city values contained misspellings or were populated with names of other cities in Illinois. To counteract this I look for the substring 'chicago' in every city cell. When a city does not contain the chicago substring, I remove the original value and insert 'non-chicago address, attention required' in its place meaning the address or the location column should be used to determine which city the facility is in. Also one city value used was \"chcicago\". As looking for the substring \"chicago\" would not work in this case I look specifically for this value also and change it to \"chicago\".\n",
    "\n",
    "\n",
    "Also the dates were in the format mm/dd/yyyy. To adjust this I split the date on the occurence of the \"/\" and reconstruct the date so it is in the format of dd/mm/yyyy. I also allow for dates that contain hyphens instead of forward slashes, if they occur I change them to forward slashes.\n",
    "\n",
    "\n",
    "When working with the Inspection type column I noticed numerous faults. One of the values present in this column was \"two people ate and got sick\". To me this is not categorical, therefore I replace that string with \"suspected food poisoning\" which is another category within this column.\n",
    "\n",
    "\n",
    "Also there were numerous different types of canvass inspections most of which had different spellings of the word canvass. Therefore I ammended each of these spelling mistakes by using the replace function and explicitly stating the error and the replacement value. Another error in the Inspection Type column is when the user performing the inspection appears to leave reminders in the inspection type value e.g 'finish complaint inspection from 5 18 10'. As this Inspection type is in relation to a a complaint I will change the value in the cell to 'complaint'.\n",
    "\n",
    "\n",
    "I also noticed errors with duplicate license numbers where the license number is 0. As this license number was being assigned to numerous different premises which is incorrect according to the dataset description linked below. I will replace any row with a license number 0 to 'unknown'\n",
    "\n",
    "\n",
    "Regarding duplicates in the csv file, if you open the data in excel and highlight every column except the inspection id column and then press the remove duplicates function in the data tab, it says there are appoximately 87 duplicates. As the inspection ID was different for these, then technically the rows are not duplicated and hence I did not remove them.\n",
    "Dataset description: https://data.cityofchicago.org/api/assets/BAD5301B-681A-4202-9D25-51B2CAE672FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.01 s, sys: 180 ms, total: 2.19 s\n",
      "Wall time: 2.21 s\n",
      "Number of unique names before:  24895\n",
      "Number of unique names after:  24490\n",
      "CPU times: user 803 ms, sys: 19.1 ms, total: 822 ms\n",
      "Wall time: 819 ms\n",
      "CPU times: user 2.3 s, sys: 47.9 ms, total: 2.34 s\n",
      "Wall time: 2.34 s\n",
      "CPU times: user 4.31 s, sys: 60.3 ms, total: 4.37 s\n",
      "Wall time: 4.36 s\n",
      "CPU times: user 61.6 ms, sys: 16.8 ms, total: 78.4 ms\n",
      "Wall time: 77.2 ms\n",
      "CPU times: user 4.36 s, sys: 19.3 ms, total: 4.38 s\n",
      "Wall time: 4.38 s\n",
      "CPU times: user 3.49 s, sys: 14.1 ms, total: 3.5 s\n",
      "Wall time: 3.5 s\n",
      "CPU times: user 4.55 s, sys: 11.3 ms, total: 4.56 s\n",
      "Wall time: 4.56 s\n",
      "CPU times: user 3.21 s, sys: 11.2 ms, total: 3.22 s\n",
      "Wall time: 3.22 s\n",
      "CPU times: user 4.07 s, sys: 92.1 ms, total: 4.16 s\n",
      "Wall time: 4.22 s\n",
      "CPU times: user 29.2 s, sys: 475 ms, total: 29.6 s\n",
      "Wall time: 29.7 s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def dba_names(data):\n",
    "    dba_names = data['DBA Name']\n",
    "    print('Number of unique names before: ', len({items for items in dba_names}))\n",
    "    \n",
    "    column_names = ['DBA Name', 'AKA Name']\n",
    "    for column in column_names:\n",
    "        data[column] = data[column].str.lower()\n",
    "        data[column] = data[column].str.strip(' ')\n",
    "        data[column] = data[column].str.replace(',', '')\n",
    "        data[column] = data[column].str.replace('.', '')\n",
    "        data[column] = data[column].str.replace('-', '')\n",
    "        data[column] = data[column].str.replace('/', '')\n",
    "    \n",
    "    new_dba_names = data['DBA Name']\n",
    "    print('Number of unique names after: ', len({items for items in new_dba_names}))\n",
    "    return data\n",
    "    \n",
    "\n",
    "def ammend_location_data(data):\n",
    "    def fill_location(row):\n",
    "        if pd.isnull(row['Location']):\n",
    "            new_location = str((row['Latitude'],  row['Longitude']))\n",
    "            return new_location\n",
    "        \n",
    "    data['Location'] = data.apply(fill_location, axis=1) # apply change date function to every row\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def missing_names(data):\n",
    "    def fill_DBA(row):\n",
    "        if pd.isnull(row['DBA Name']):\n",
    "            return row['AKA Name']\n",
    "    def fill_AKA(row):\n",
    "        if pd.isnull(row['AKA Name']):\n",
    "            return row['DBA Name']\n",
    "    \n",
    "    data['DBA Name'] = data.apply(fill_DBA, axis=1) \n",
    "    data['AKA Name'] = data.apply(fill_AKA, axis=1) \n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def remove_columns(data):\n",
    "    # axis 1 means its applied to each row whereas axis 0 means its applied to each column\n",
    "    data = data.drop(['State'], axis=1) \n",
    "    data = data.drop(['Latitude'], axis=1)\n",
    "    data = data.drop(['Longitude'], axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def ammend_city(data):\n",
    "    def fill_city(row):\n",
    "        if 'chicago' in str(row['City']).lower() and str(row['City']).lower() != 'chicago':\n",
    "            city = 'chicago' \n",
    "            return city\n",
    "        \n",
    "        if 'chicago' not in str(row['City']).lower():\n",
    "            city = 'non-chicago address, attention required'\n",
    "            return city\n",
    "    data['City'] = data.apply(fill_city, axis=1)\n",
    "    return data\n",
    "    \n",
    "    # THE COMMENTED CODE BELOW TAKES APPROX. 12 SECONDS\n",
    "    '''for index, rows in data.iterrows():\n",
    "        if 'chicago' in str(data.loc[index, 'City']).lower() and str(data.loc[index, 'City']).lower() != 'chicago':\n",
    "            data.loc[index, 'City'] = 'chicago' \n",
    "        if 'chicago' not in str(data.loc[index, 'City']).lower():\n",
    "            data.loc[index, 'City'] = 'non-chicago address, attention required'\n",
    "    return data'''\n",
    "\n",
    "\n",
    "def ammend_dates(data):\n",
    "    def change_date(row):\n",
    "        if pd.notnull(row['Inspection Date']):\n",
    "            old_date = str(row['Inspection Date']).split('/')\n",
    "            new_date = old_date[1] + '/' + old_date[0] + '/' + old_date[2]\n",
    "            return new_date\n",
    "            \n",
    "    data['Inspection Date'] = data.apply(change_date, axis=1) # apply change date function to every row\n",
    "    \n",
    "    return data\n",
    " \n",
    "\n",
    "def ammend_inspections(data):\n",
    "    def change_inspection(row):\n",
    "        if str(row['Inspection Type']).lower() == 'two people ate and got sick.':\n",
    "            inspection_desc = 'Suspected food poisoning'\n",
    "            return inspection_desc\n",
    "        elif 'canv' in str(str(row['Inspection Type']).lower()):\n",
    "            inspection_desc = 'Canvass'\n",
    "            return inspection_desc\n",
    "        elif 'fire' in str(str(row['Inspection Type']).lower()):\n",
    "            inspection_desc = 'Fire Complaint'\n",
    "            return inspection_desc\n",
    "        elif 'out' in str(str(row['Inspection Type']).lower()) and 'business' in str(str(row['Inspection Type']).lower()):\n",
    "            inspection_desc = 'Out of business'\n",
    "            return inspection_desc\n",
    "        elif 'finish complaint inspection from 5 18 10' in str(str(row['Inspection Type']).lower()):\n",
    "            inspection_desc = 'Complaint'\n",
    "            return inspection_desc\n",
    "            \n",
    "            \n",
    "    data['Inspection Type'] = data.apply(change_inspection, axis=1) # apply change date function to every row\n",
    "    return data\n",
    " \n",
    "    \n",
    "def ammend_license_num(data):\n",
    "    def change_lisence(row):\n",
    "        if pd.notnull(row['License #']):\n",
    "            if row['License #'] == 0:\n",
    "                unknown = 'Unknown'\n",
    "                return unknown\n",
    "            \n",
    "    data['License #'] = data.apply(change_lisence, axis=1) # apply change date function to every row\n",
    "    \n",
    "    return data  \n",
    "            \n",
    "                    \n",
    "#  need to supply parse_dates function otherwise dates appear as none as it only accepts strings, ints and floats when\n",
    "#  reading csv files, noticeably has a big impact on execution time (approx. 18 second increase)\n",
    "data = pd.read_csv('Food_Inspections.csv', infer_datetime_format=True) \n",
    "data = dba_names(data)\n",
    "data = ammend_location_data(data)\n",
    "data = missing_names(data)\n",
    "data = remove_columns(data)\n",
    "data = ammend_city(data)\n",
    "data = ammend_dates(data)\n",
    "data = ammend_inspections(data)\n",
    "data = ammend_license_num(data)\n",
    "data.to_csv('Output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
